---
title: "Mid_Term_Project"
author: "Data Pandas"
date: "2025-03-10"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r init, include=F}
# The package "ezids" (EZ Intro to Data Science) includes a lot of the helper functions we developed for the course. 
# Some of the frequently used functions are loadPkg(), xkabledply(), xkablesummary(), uzscale(), etc.
# Once installed, load the library.
library(ezids)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.


Lets load the dataset:

```{r, include=T}

BikeShare_Data <- data.frame(read.csv("202501-capitalbikeshare-tripdata.csv"))

```

Before Cleaning the data, Let's see a few Rows in the dataset.

```{r, results='markup'}
head(BikeShare_Data, n=5)
tail(BikeShare_Data, n=3)
```

Let's see the structure of the variables

```{r}
str(BikeShare_Data)
```

Now, let's get the summary of the raw data,

```{r}
summary(BikeShare_Data)
```

Now, Let's go into Data Preprocessing,

We should remove the unwanted columns like start_lat, start_lng, end_lat, end_lng, start_station_id, end_station_id from our dataset since those columns will be irrelevant. Also, convert the member_casual variable into factor.

```{r}

BikeShare_Data$end_lat <- NULL
BikeShare_Data$end_lng <- NULL
BikeShare_Data$start_lat <- NULL
BikeShare_Data$start_lng <- NULL
BikeShare_Data$member_casual <- as.factor(BikeShare_Data$member_casual)
str(BikeShare_Data)
```

There might be some duplicate values in the data. We removed them.

```{r}
duplicates_count <- sum(duplicated(BikeShare_Data))
duplicates_count

BikeShare_Data <- BikeShare_Data[!duplicated(BikeShare_Data), ]

cat("Number of duplicates removed:", duplicates_count, "\n")
cat("Rows remaining after removing duplicates:", nrow(BikeShare_Data), "\n")
str(BikeShare_Data)
```

There are no duplicate values at all! Capital Bikeshare is maintaining it's data very accurately.

We will check for the missing values in the dataset and remove the rows with missing values.
```{r}
missing_values <- colSums(is.na(BikeShare_Data))
missing_values
```

There are many missing values in the columns start_station_id, end_station_id. Since the start station and end station details are crucial for our analysis, its better if we remove the rows where the start station and end station are missing.

```{r}
BikeShare_Data <- BikeShare_Data[!is.na(BikeShare_Data$start_station_id) & 
                                 !is.na(BikeShare_Data$end_station_id), ]
colSums(is.na(BikeShare_Data))

str(BikeShare_Data)
```

There are a few rides which started in 31st Dec 2024 but ended on 1st Jan 2025. We will remove those rows and then put them in an oredr according to the time they were started at.
```{r}
BikeShare_Data <- BikeShare_Data[BikeShare_Data$started_at >= "2025-01-01", ]
BikeShare_Data$started_at <- as.POSIXct(BikeShare_Data$started_at)
BikeShare_Data$ended_at <- as.POSIXct(BikeShare_Data$ended_at)

BikeShare_Data <- BikeShare_Data[order(BikeShare_Data$started_at), ]
nrow(BikeShare_Data)

```

We have created a few new columns named "trip_duration",  which will be helpful for future analysis. Also, we removed the outliers.
```{r}

BikeShare_Data$trip_duration <- as.numeric(difftime(BikeShare_Data$ended_at, 
                                                    BikeShare_Data$started_at, 
                                                    units = "mins"))

BikeShare_Data$hour_of_day <- format(BikeShare_Data$started_at, "%H")

BikeShare_Data$day_of_week <- weekdays(BikeShare_Data$started_at)

BikeShare_Data$day_of_week <- factor(BikeShare_Data$day_of_week, 
                                     levels = c("Monday", "Tuesday", "Wednesday", 
                                                "Thursday", "Friday", "Saturday", "Sunday"),
                                     ordered = TRUE)

BikeShare_Data <- BikeShare_Data[BikeShare_Data$trip_duration > 0 & BikeShare_Data$trip_duration < 720,]

head(BikeShare_Data)
```

Now, lets do some EDA.

We'll start with some simple histograms. 

```{r}
library(ggplot2)

#regular bikes vs. ebikes
ggplot(BikeShare_Data, aes(x = rideable_type, fill = rideable_type)) +
  geom_bar() +
  labs(title = "Distribution of Rideable Types",
       x = "Rideable Type",
       y = "Count") +
  scale_fill_manual(values = c("electric_bike" = "navy", "classic_bike" = "lightblue")) +
  theme_minimal()
```

This shows us that Ebikes were more popular than classic bikes. 

```{r}
#Since we're interested in when how usage varied, let's look at the number of rides per weekday

ggplot(BikeShare_Data, aes(x = day_of_week, fill = day_of_week)) +
  geom_bar() +
  labs(title = "Number of Bike Rides per Weekday",
       x = "Weekday",
       y = "Number of Rides") +
scale_fill_manual(values = c("#b3cde3", "#8c96c6", "#4b6fa5", "#2b5c8a", "#104e8b", "#08306b", "#041e42")) +   # Shades of blue to match our powerpoint!
  theme_minimal() +
  theme(legend.position = "none")  
```
This shows us that bike rides peak on Thursday. They are very similar for the weekend days of Saturday and Sunday. Monday is the least popular day for BikeShare rides.

```{r}
#Again, since we're interested in how usage varies, let's look at how frequently BikeShare rides are occurring throughout the course of the day.

ggplot(BikeShare_Data, aes(x = factor(hour_of_day), fill = ..count..)) +
  geom_bar(color = "black") +
  scale_fill_gradient(low = "lightblue", high = "darkblue") +
  labs(title = "Bike Usage by Hour of the Day",
       x = "Hour of the Day",
       y = "Number of Rides") +
  theme_minimal()
```

This shows us the rush hour spikes at 8AM and 5PM, when BikeShare users are likely commuting.

If our hypothesis that commuting to work is what is driving the spikes at those times, we should see a difference between weekday and weekend usage.

```{r}
#Comparing usage by time of day on weekdays vs. weekends

library(dplyr)

# Let's group our existing day_of_week variable to create categories for Weekday vs. Weekend for easy comparison
BikeShare_Data <- BikeShare_Data %>%
  mutate(day_type = ifelse(day_of_week %in% c("Saturday", "Sunday"), "Weekend", "Weekday"))

ggplot(BikeShare_Data, aes(x = factor(hour_of_day), fill = day_type)) +
  geom_bar(position = "dodge", color = "black") +
  facet_wrap(~day_type) +  # Creates separate plots for Weekday and Weekend
  labs(title = "Bike Usage by Hour: Weekdays vs. Weekends",
       x = "Hour of the Day",
       y = "Number of Rides") +
  scale_fill_manual(values = c("Weekday" = "#87CEEB", "Weekend" = "#0000CD")) +
  scale_x_discrete(breaks = c("08", "17"))
theme_minimal()

```

We can clearly the see difference in scale but it's hard to interpret. Let's adjust it to highlight where the biggest differences in usage per hour on weekdays vs. weekends is. 

```{r}
library(ggplot2)
library(dplyr)
library(tidyr)

# Calculate ride counts for each hour and day type and the difference between them so we can highlight it visually.
hourly_counts <- BikeShare_Data %>%
  group_by(hour_of_day, day_type) %>%
  summarise(rides = n(), .groups = "drop") %>%
   spread(key = day_type, value = rides, fill = 0) %>% 
  mutate(difference = abs(Weekday - Weekend)) 

# Find the top 2 hours with the greatest difference. If our hypothesis is correct it will be 08 and 17.
top_diff_hours <- hourly_counts %>%
  top_n(2, difference) %>%
  pull(hour_of_day)

BikeShare_Data <- BikeShare_Data %>%
  mutate(highlight = ifelse(hour_of_day %in% top_diff_hours, "Highlighted", "Normal"))

ggplot(BikeShare_Data, aes(x = factor(hour_of_day), fill = highlight)) +
  geom_bar(position = "dodge", color = "black") +
  facet_wrap(~day_type) +  
  labs(title = "Bike Usage by Hour: Major Difference Indicate Commuting Trends",
       x = "Hour of the Day",
       y = "Number of Rides") +
  scale_fill_manual(values = c("Highlighted" = "#007FFF", "Normal" = "gray")) +  
    scale_x_discrete(breaks = as.character(top_diff_hours)) + 
  guides(fill = "none") +
  theme_minimal()

```

Much better! This graph clearly shows the distinction between ridership during peak commute times on weekday vs. weekends.

```{r}
#Let's count the difference so we can add some granularity to these visible differences. 
ride_counts <- BikeShare_Data %>%
  filter(hour_of_day %in% c(8, 17)) %>%  # Filter for 08:00 and 17:00
  group_by(day_of_week, hour_of_day) %>%  # Group by day of week and hour
  summarise(num_rides = n(), .groups = "drop")  # Count the number of rides

ride_counts
```

We can also look at the difference in terms of averages. 
```{r}
avg_rides <- BikeShare_Data %>%
  group_by(day_type) %>%
  summarise(avg_rides = n() / length(unique(day_of_week)), .groups = "drop")

avg_rides
```


We are also interested in which locations are the most popular. Since we have two location variables, start_station_name and end_station_name, let's start by looking at them individually.

```{r}
#First we'll count both variables and restrict the data we want to visualize to the top 10.
start_station_counts <- BikeShare_Data %>%
  count(start_station_name, sort = TRUE) %>%
  top_n(10, n)

end_station_counts <- BikeShare_Data %>%
  count(end_station_name, sort = TRUE) %>%
  top_n(10, n) 
```


```{r}
#plotting the most popular start stations
ggplot(start_station_counts, aes(x = reorder(start_station_name, n), y = n, fill = start_station_name)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  labs(title = "Top 10 Most Popular Start Stations",
       x = "Start Station",
       y = "Number of Rides") +
    guides(fill = "none") +
  theme_minimal() +
  scale_fill_manual(values = scales::brewer_pal(palette = "Blues")(10)) 
```

```{r}
#plotting the most popular end stations
ggplot(end_station_counts, aes(x = reorder(end_station_name, n), y = n, fill = end_station_name)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  labs(title = "Top 10 Most Popular End Stations",
       x = "End Station",
       y = "Number of Rides") +
  guides(fill = "none") +
  theme_minimal() +
  scale_fill_manual(values = scales::brewer_pal(palette = "Blues")(10)) 
```

Now we'll combine them to see which stations get the most overall traffic. 

```{r}
#plotting most popular stations by combined start and stop measure.
combined_station_data <- BikeShare_Data %>%
  gather(key = "station_type", value = "station_name", start_station_name, end_station_name) %>%
  count(station_name, sort = TRUE) %>%
  top_n(10, n)  # Top 10 stations

# Plot Combined Start and End Stations
ggplot(combined_station_data, aes(x = reorder(station_name, n), y = n, fill = station_name)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  labs(title = "Top 10 Most Popular Stations",
       x = "Station",
       y = "Number of Rides") +
   guides(fill = "none") +
  theme_minimal() +
  scale_fill_manual(values = scales::brewer_pal(palette = "Blues")(10)) 
```

